{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import cvlib as cv\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from mtcnn import MTCNN\n",
    "# from keras.utils import np_utils\n",
    "from keras import utils\n",
    "\n",
    "from sklearn.metrics import f1_score as sklearn_f1_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T18:41:24.211583Z",
     "end_time": "2023-05-19T18:41:24.995612Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def process_images(images_folder, labels_folder, output_folder):\n",
    "    # Make the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate over each file in the image directory\n",
    "    for img_name in os.listdir(images_folder):\n",
    "        if img_name.endswith(\".jpeg\") or img_name.endswith(\".png\"):\n",
    "            # Derive the corresponding label filename\n",
    "            label_name = img_name.rsplit('.', 1)[0] + '.txt'\n",
    "\n",
    "            # Create paths for the image and label\n",
    "            img_path = os.path.join(images_folder, img_name)\n",
    "            label_path = os.path.join(labels_folder, label_name)\n",
    "\n",
    "            if os.path.exists(label_path):\n",
    "                with open(label_path, 'r') as f:\n",
    "                    coords = f.readline().strip().split()\n",
    "                    if len(coords) == 5:\n",
    "                        class_id, x_center, y_center, width, height = coords\n",
    "                        with Image.open(img_path) as img:\n",
    "                            img_width, img_height = img.size\n",
    "                            x_center, y_center, width, height = float(x_center), float(y_center), float(width), float(height)\n",
    "\n",
    "                            # Convert normalized coordinates to pixel values\n",
    "                            x_center *= img_width\n",
    "                            y_center *= img_height\n",
    "                            width *= img_width\n",
    "                            height *= img_height\n",
    "\n",
    "                            # Convert center coordinates to top-left and bottom-right\n",
    "                            x1, y1 = int(x_center - width/2), int(y_center - height/2)\n",
    "                            x2, y2 = int(x_center + width/2), int(y_center + height/2)\n",
    "\n",
    "                            # Crop the image\n",
    "                            cropped_img = img.crop((x1, y1, x2, y2))\n",
    "                            cropped_img.save(os.path.join(output_folder, img_name))\n",
    "                    else:\n",
    "                        print(f\"Unexpected format in {label_path}. Contents: {coords}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    images_folder = \"C:/Users/mupaj/Documents/Apps/cv_weapon_detection/data\" \\\n",
    "                    \"/big/archive (2)/weapon_detection/train/images\"\n",
    "    labels_folder = \"C:/Users/mupaj/Documents/Apps/cv_weapon_detection/data\" \\\n",
    "                    \"/big/archive (2)/weapon_detection/train/labels\"\n",
    "    output_folder = \"C:/Users/mupaj/Documents/Apps/cv_weapon_detection/data\" \\\n",
    "                    \"/big/archive (2)/weapon_detection/train/cropped\"\n",
    "\n",
    "    process_images(images_folder, labels_folder, output_folder)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mupaj\\Documents\\Apps\\cv_weapon_detection\\venv\\lib\\site-packages\\imgaug\\imgaug.py:184: DeprecationWarning: Function `ContrastNormalization()` is deprecated. Use `imgaug.contrast.LinearContrast` instead.\n",
      "  warn_deprecated(msg, stacklevel=3)\n",
      "C:\\Users\\mupaj\\Documents\\Apps\\cv_weapon_detection\\venv\\lib\\site-packages\\PIL\\Image.py:970: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Define your desired image size\n",
    "TARGET_SIZE = (224, 224)\n",
    "\n",
    "# Define the augmentation sequence\n",
    "augmenter = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),  # Horizontal flips\n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},  # Scaling\n",
    "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},  # Translation\n",
    "        rotate=(-30, 30),  # Rotation\n",
    "        shear=(-16, 16)  # Shearing\n",
    "    ),\n",
    "    iaa.PerspectiveTransform(scale=(0.01, 0.15)),  # Perspective transformations\n",
    "    iaa.Multiply((0.8, 1.2)),  # Change brightness\n",
    "    iaa.ContrastNormalization((0.7, 1.3)),  # Change contrast\n",
    "    iaa.GaussianBlur(sigma=(0, 3.0)),  # Gaussian Blur\n",
    "    iaa.AdditiveGaussianNoise(scale=(0, 0.05*255)),  # Noise\n",
    "    iaa.Crop(percent=(0, 0.1)),  # Random cropping\n",
    "    iaa.LinearContrast((0.7, 1.3)),  # Improve or worsen contrast\n",
    "    iaa.ChangeColorspace(to_colorspace=\"GRAY\"),  # Convert images to grayscale\n",
    "    iaa.ElasticTransformation(alpha=50, sigma=5)  # Elastic transformations\n",
    "])\n",
    "\n",
    "augmenters = [\n",
    "    iaa.Fliplr(0.5),  # Horizontal flips\n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},  # Scaling\n",
    "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},  # Translation\n",
    "        rotate=(-30, 30),  # Rotation\n",
    "        shear=(-16, 16)  # Shearing\n",
    "    ),\n",
    "    iaa.PerspectiveTransform(scale=(0.01, 0.15)),  # Perspective transformations\n",
    "    iaa.Multiply((0.8, 1.2)),  # Change brightness\n",
    "    iaa.ContrastNormalization((0.7, 1.3)),  # Change contrast\n",
    "    iaa.GaussianBlur(sigma=(0, 3.0)),  # Gaussian Blur\n",
    "    iaa.AdditiveGaussianNoise(scale=(0, 0.05*255)),  # Noise\n",
    "    iaa.Crop(percent=(0, 0.1)),  # Random cropping\n",
    "    iaa.LinearContrast((0.7, 1.3)),  # Improve or worsen contrast\n",
    "    iaa.ChangeColorspace(to_colorspace=\"GRAY\"),  # Convert images to grayscale\n",
    "    iaa.ElasticTransformation(alpha=50, sigma=5)  # Elastic transformations\n",
    "]\n",
    "\n",
    "def resize_image(image, target_size):\n",
    "    return image.resize(target_size)\n",
    "\n",
    "\n",
    "def apply_augmentation(image, augmenter):\n",
    "    # Convert PIL image to numpy array\n",
    "    image_np = np.array(image)\n",
    "    # Apply the augmentation\n",
    "    image_aug = augmenter(image=image_np)\n",
    "    # Convert back to PIL Image\n",
    "    return Image.fromarray(image_aug)\n",
    "\n",
    "def process_images(images_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for img_name in os.listdir(images_folder):\n",
    "        if img_name.endswith((\".jpeg\", \".png\", \".jpg\")):\n",
    "            img_path = os.path.join(images_folder, img_name)\n",
    "            with Image.open(img_path).convert('RGB') as img:\n",
    "                img_resized = resize_image(img, TARGET_SIZE)\n",
    "                for idx, augmenter in enumerate(augmenters):\n",
    "                    img_augmented = apply_augmentation(img_resized, augmenter)\n",
    "                    # Generate a unique name for each augmented image\n",
    "                    base_name, ext = os.path.splitext(img_name)\n",
    "                    new_name = f\"{base_name}_aug{idx}{ext}\"\n",
    "                    img_augmented.save(os.path.join(output_folder, new_name))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    images_folder = \"C:/Users/mupaj/Documents/Apps/cv_weapon_detection/data\" \\\n",
    "                    \"/big/weapons/weapon_detection/train/cropped\"\n",
    "    output_folder = \"C:/Users/mupaj/Documents/Apps/cv_weapon_detection/data\" \\\n",
    "                    \"/big/weapons/weapon_detection/train/augmented_2\"\n",
    "\n",
    "    process_images(images_folder, output_folder)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Resizing Cropped Images and save them\n",
    "\"\"\"\n",
    "def resize_image(input_dir,output_dir):\n",
    "\n",
    "    # specify the new dimensions you want for the images\n",
    "    new_dimensions = (40, 40)  # you should change this to the dimensions you want\n",
    "\n",
    "    # create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # add/modify image file types here\n",
    "            img = Image.open(os.path.join(input_dir, filename))\n",
    "            img.thumbnail(new_dimensions)\n",
    "            img.save(os.path.join(output_dir, filename))\n",
    "\n",
    "resize_image(\"C:/Users/mupaj/Documents/Apps/final_vc/FaceData/man_croped/\",\"C:/Users/mupaj/Documents/Apps/final_vc/FaceData/man_resized/\")\n",
    "\n",
    "resize_image(\"C:/Users/mupaj/Documents/Apps/final_vc/FaceData/woman_croped/\",\"C:/Users/mupaj/Documents/Apps/final_vc/FaceData/woman_resized/\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T18:31:40.553398Z",
     "end_time": "2023-05-19T18:31:40.620197Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find F1 Score\n",
    "\"\"\"\n",
    "\n",
    "def compute_f1_score(test_generator, model):\n",
    "\n",
    "    # Generate a list of labels\n",
    "    test_labels = test_generator.classes\n",
    "    # Convert the labels to categorical\n",
    "    test_labels = utils.to_categorical(test_labels, num_classes=len(test_generator.class_indices))\n",
    "\n",
    "    # Make the model predictions\n",
    "    predictions = model.predict(test_generator)\n",
    "\n",
    "    # Convert predictions classes to one hot vectors\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    # Convert test observations to one hot vectors\n",
    "    true_classes = np.argmax(test_labels, axis=1)\n",
    "\n",
    "    # compute the confusion matrix\n",
    "    f1Score = sklearn_f1_score(true_classes, predicted_classes, average='macro')\n",
    "\n",
    "    print(\"F1 Score: \", f1Score)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T18:48:52.180878Z",
     "end_time": "2023-05-19T18:48:52.193165Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2  # OpenCV for heatmap processing\n",
    "\n",
    "def generate_heatmap(img_path, model):\n",
    "    # Preprocess the image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (150, 150))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_tensor = np.expand_dims(img, axis=0)\n",
    "    img_tensor /= 255.  # Model-specific preprocessing method\n",
    "\n",
    "    # Get the model's prediction\n",
    "    preds = model.predict(img_tensor)\n",
    "    predicted_class = np.argmax(preds[0])\n",
    "\n",
    "    # Extract the output of the last convolutional layer in the model\n",
    "    last_conv_layer = model.get_layer(index=-4)  # Assuming it's the last conv layer\n",
    "\n",
    "    # Compute the gradient of the class' output value with respect to the feature map\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output = last_conv_layer(img_tensor)\n",
    "        tape.watch(last_conv_layer_output)\n",
    "        class_channel = model.layers[-1](last_conv_layer_output)\n",
    "        loss = class_channel[:, predicted_class]\n",
    "\n",
    "    grads = tape.gradient(loss, last_conv_layer_output)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # Multiply each channel in the feature map array by the gradient importance\n",
    "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
    "    for i in range(last_conv_layer_output.shape[-1]):\n",
    "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
    "\n",
    "    # Average the feature maps along the channel dimension resulting in a heatmap of size 3x3\n",
    "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
    "\n",
    "    # Normalize the heatmap between 0 & 1 for visualization\n",
    "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "    # Superimpose the heatmap over the original image\n",
    "    superimposed_img = heatmap * 0.4 + img\n",
    "    cv2.imwrite('heatmap.jpg', superimposed_img)\n",
    "\n",
    "    plt.imshow(superimposed_img.astype('uint8'))\n",
    "    plt.show()\n",
    "\n",
    "# # Usage:\n",
    "# img_path = \"path_to_an_image.jpg\"\n",
    "# generate_heatmap(img_path, model)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "\n",
    "\n",
    "def generate_heatmaps_for_images(img_paths, model, epoch):\n",
    "    for idx, img_path in enumerate(img_paths):\n",
    "        generate_heatmap(img_path, model)\n",
    "        plt.savefig(f\"heatmap_epoch_{epoch}_img_{idx}.png\")\n",
    "        plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8642 images belonging to 1 classes.\n",
      "Found 2160 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mupaj\\Documents\\Apps\\cv_weapon_detection\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271/271 [==============================] - 64s 233ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f1_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 112\u001B[0m\n\u001B[0;32m    109\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m train_generator, validation_generator, model\n\u001B[0;32m    111\u001B[0m \u001B[38;5;66;03m# Usage:\u001B[39;00m\n\u001B[1;32m--> 112\u001B[0m train_generator, validation_generator, model \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m\\\u001B[49m\n\u001B[0;32m    113\u001B[0m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mC:/Users/mupaj/Documents/Apps/cv_weapon_detection/data/big\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[0;32m    114\u001B[0m \u001B[43m                 \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/weapons/weapon_detection/train/augmented_2\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[1], line 55\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(dataset_dir)\u001B[0m\n\u001B[0;32m     52\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(train_generator, validation_data\u001B[38;5;241m=\u001B[39mvalidation_generator, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m)\n\u001B[0;32m     54\u001B[0m \u001B[38;5;66;03m# Compilation\u001B[39;00m\n\u001B[1;32m---> 55\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[43mf1_score\u001B[49m])\n\u001B[0;32m     58\u001B[0m \u001B[38;5;66;03m# CSV for results\u001B[39;00m\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresults.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m, newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m file:\n",
      "\u001B[1;31mNameError\u001B[0m: name 'f1_score' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "def train_model(dataset_dir):\n",
    "\n",
    "    # ImageDataGenerator for data augmentation and rescaling\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255, validation_split=0.2) # assuming 20% validation split\n",
    "\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        dataset_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary', # This line\n",
    "        subset='training',\n",
    "        seed=42)\n",
    "\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        dataset_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary', # And this line\n",
    "        subset='validation')\n",
    "\n",
    "\n",
    "    # You may want to create another ImageDataGenerator for test without data augmentation later\n",
    "\n",
    "    # Model creation\n",
    "    # Create the model architecture.\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.add(Dense(len(train_generator.class_indices), activation='softmax'))\n",
    "\n",
    "    # Compile the model.\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model.\n",
    "    model.fit(train_generator, validation_data=validation_generator, epochs=1, batch_size=32)\n",
    "\n",
    "    # Compilation\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', f1_score])\n",
    "\n",
    "\n",
    "    # CSV for results\n",
    "    with open(\"results.csv\", \"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Epoch\", \"Accuracy\", \"Loss\", \"Validation Accuracy\", \"Validation Loss\", \"Time (seconds)\"])\n",
    "\n",
    "        # Training and data collection\n",
    "        for epoch in range(1, 2):  # for 5 epochs, adjust as necessary\n",
    "            start_time = time.time()\n",
    "            history = model.fit(train_generator, validation_data=validation_generator, epochs=epoch,\n",
    "                                initial_epoch=epoch-1, batch_size=32, verbose=1)\n",
    "            end_time = time.time()\n",
    "\n",
    "            # Saving epoch data to CSV\n",
    "            writer.writerow([epoch,\n",
    "                             history.history['accuracy'][-1],\n",
    "                             history.history['loss'][-1],\n",
    "                             history.history['val_accuracy'][-1],\n",
    "                             history.history['val_loss'][-1],\n",
    "                             end_time - start_time])\n",
    "\n",
    "            # Plotting accuracy and loss after each epoch\n",
    "            plt.figure(figsize=(12, 5))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "            plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "            plt.legend()\n",
    "            plt.title(f\"Epoch {epoch} Accuracy\")\n",
    "\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(history.history['loss'], label='Train Loss')\n",
    "            plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "            plt.legend()\n",
    "            plt.title(f\"Epoch {epoch} Loss\")\n",
    "\n",
    "            plt.savefig(f\"epoch_{epoch}_plot.png\")\n",
    "            plt.show()\n",
    "\n",
    "    # Heatmaps or feature visualizations are a bit more involved and may be implemented separately.\n",
    "    # Saving the final model\n",
    "    model.save('model.h5')\n",
    "\n",
    "    # img_paths = [\"C:/Users/mupaj/Documents/Apps/cv_weapon_detection/data/big\"\n",
    "    #              \"/weapons/weapon_detection/train/OTHER/path_to_image1\"\n",
    "    #              \".jpg\",\n",
    "    #              \"C:/Users/mupaj/Documents/Apps/cv_weapon_detection/data/big\"\n",
    "    #              \"/weapons/weapon_detection/train/OTHER/path_to_image2.jpg\"]  # add paths to the\n",
    "    # representative images\n",
    "    # For demonstration, let's generate heatmaps at the end of training.\n",
    "    # However, you could call this function at any epoch if desired.\n",
    "    # generate_heatmaps_for_images(img_paths, model, epoch=1)\n",
    "\n",
    "    return train_generator, validation_generator, model\n",
    "\n",
    "# Usage:\n",
    "train_generator, validation_generator, model = train_model\\\n",
    "    (\"C:/Users/mupaj/Documents/Apps/cv_weapon_detection/data/big\"\n",
    "                 \"/weapons/weapon_detection/train/augmented_2\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5351 images belonging to 2 classes.\n",
      "Found 324 images belonging to 2 classes.\n",
      "Found 829 images belonging to 2 classes.\n",
      "168/168 [==============================] - 62s 363ms/step - loss: 0.3137 - accuracy: 0.8903 - val_loss: 0.4335 - val_accuracy: 0.8611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mupaj\\Documents\\Apps\\cv_weapon_detection\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 2s 73ms/step\n",
      "F1 Score:  0.5029570987833983\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train Model\n",
    "\"\"\"\n",
    "def train_model(train_dir,validation_dir,test_dir):\n",
    "\n",
    "    # Define ImageDataGenerators for training, validation and testing\n",
    "    # This will handle preprocessing, image augmentation, and splitting.\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    test_generator = datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    # Create the model architecture.\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(len(train_generator.class_indices), activation='softmax'))\n",
    "\n",
    "    # Compile the model.\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model.\n",
    "    model.fit(train_generator, validation_data=validation_generator, epochs=1, batch_size=32)\n",
    "\n",
    "    # Save the model for later use.\n",
    "    model.save('model.h5')\n",
    "\n",
    "    compute_f1_score(test_generator,model)\n",
    "\n",
    "    return train_generator, validation_generator, test_generator, model\n",
    "\n",
    "\n",
    "\n",
    "train_generator, validation_generator, test_generator, model = train_model\\\n",
    "    (\"data/train\",\n",
    "     \"data/val\",\n",
    "     \"data/test\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T18:56:25.197275Z",
     "end_time": "2023-05-19T18:56:33.907995Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Assuming your model is defined and named \"model\"\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "visible1 = Input(shape=(150, 150, 3))\n",
    "visible2 = Input(shape=(150, 150, 3))\n",
    "\n",
    "# Architecture for visible1\n",
    "x1 = Conv2D(32, (3, 3), activation='relu')(visible1)\n",
    "x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "x1 = Conv2D(64, (3, 3), activation='relu')(x1)\n",
    "x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "x1 = Flatten()(x1)\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "\n",
    "# Architecture for visible2\n",
    "x2 = Conv2D(32, (3, 3), activation='relu')(visible2)\n",
    "x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "x2 = Conv2D(64, (3, 3), activation='relu')(x2)\n",
    "x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "x2 = Flatten()(x2)\n",
    "x2 = Dense(128, activation='relu')(x2)\n",
    "\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "merged = concatenate([x1, x2])\n",
    "output = Dense(len(train_generator.class_indices), activation='softmax')(merged)\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model = Model(inputs=[visible1, visible2], outputs=output)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dense1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# merge input models\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m merge \u001B[38;5;241m=\u001B[39m concatenate([\u001B[43mdense1\u001B[49m, dense2])\n\u001B[0;32m      3\u001B[0m output \u001B[38;5;241m=\u001B[39m Dense(\u001B[38;5;241m1\u001B[39m)(merge)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'dense1' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# merge input models\n",
    "merge = concatenate([dense1, dense2])\n",
    "output = Dense(1)(merge)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step\n",
      "Label: knife - Prediction: [[0.91997945 0.08002057]]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Label: knife - Prediction: [[0.93156785 0.0684322 ]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Label: knife - Prediction: [[0.99625945 0.00374055]]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Label: pistol - Prediction: [[0.18999398 0.810006  ]]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Label: knife - Prediction: [[0.8732139  0.12678604]]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Label: pistol - Prediction: [[5.0757435e-06 9.9999487e-01]]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Label: knife - Prediction: [[0.667418 0.332582]]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Label: pistol - Prediction: [[1.5498856e-11 1.0000000e+00]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Label: pistol - Prediction: [[1.880992e-12 1.000000e+00]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Label: pistol - Prediction: [[0.00320458 0.9967955 ]]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Label: pistol - Prediction: [[0.03773614 0.9622638 ]]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Label: pistol - Prediction: [[0.25500017 0.7449998 ]]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Label: pistol - Prediction: [[0.19230278 0.80769724]]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Label: pistol - Prediction: [[0.0971113 0.9028887]]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Label: knife - Prediction: [[0.62780863 0.3721914 ]]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Label: pistol - Prediction: [[0.01010984 0.9898901 ]]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Label: pistol - Prediction: [[9.6220183e-06 9.9999034e-01]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Label: pistol - Prediction: [[1.4615100e-06 9.9999857e-01]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Label: pistol - Prediction: [[3.0485267e-11 1.0000000e+00]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Label: pistol - Prediction: [[3.317875e-17 1.000000e+00]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Label: pistol - Prediction: [[1.6810992e-14 1.0000000e+00]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Label: pistol - Prediction: [[7.1060997e-05 9.9992895e-01]]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Label: pistol - Prediction: [[5.499637e-10 1.000000e+00]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Label: pistol - Prediction: [[1.3227941e-09 1.0000000e+00]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Label: pistol - Prediction: [[4.1398278e-05 9.9995863e-01]]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Label: knife - Prediction: [[0.89792556 0.10207451]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Label: knife - Prediction: [[0.9945669  0.00543307]]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Label: knife - Prediction: [[0.9763399  0.02366011]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Label: knife - Prediction: [[0.92295533 0.07704472]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Label: knife - Prediction: [[0.91997945 0.08002057]]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Label: knife - Prediction: [[0.91997945 0.08002057]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Label: knife - Prediction: [[0.91997945 0.08002057]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Label: knife - Prediction: [[0.91997945 0.08002057]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Label: knife - Prediction: [[0.91997945 0.08002057]]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Label: knife - Prediction: [[0.91997945 0.08002057]]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Label: knife - Prediction: [[0.91997945 0.08002057]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Label: knife - Prediction: [[0.91997945 0.08002057]]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Label: knife - Prediction: [[0.91997945 0.08002057]]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Label: knife - Prediction: [[0.91997945 0.08002057]]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Label: knife - Prediction: [[0.91997945 0.08002057]]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Label: knife - Prediction: [[0.91997945 0.08002057]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Label: knife - Prediction: [[0.91997945 0.08002057]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Label: knife - Prediction: [[0.91997945 0.08002057]]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Label: knife - Prediction: [[0.91997945 0.08002057]]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Label: knife - Prediction: [[0.91997945 0.08002057]]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Label: knife - Prediction: [[0.91997945 0.08002057]]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Label: knife - Prediction: [[0.9792154  0.02078458]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Label: pistol - Prediction: [[1.3808110e-04 9.9986196e-01]]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Label: pistol - Prediction: [[3.1445771e-07 9.9999964e-01]]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Label: pistol - Prediction: [[3.2709268e-16 1.0000000e+00]]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Label: pistol - Prediction: [[0.3437723 0.6562277]]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Label: pistol - Prediction: [[2.2490212e-08 1.0000000e+00]]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Label: knife - Prediction: [[0.9988121  0.00118798]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 56\u001B[0m\n\u001B[0;32m     50\u001B[0m     cv2\u001B[38;5;241m.\u001B[39mdestroyAllWindows()\n\u001B[0;32m     52\u001B[0m \u001B[38;5;66;03m# predict_weapon_video('C:/Users/mupaj/Documents/Apps/final_vc/data/pexels'\u001B[39;00m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;66;03m#                    '-karolina-grabowska-5243196-1920x1080-25fps.mp4')\u001B[39;00m\n\u001B[0;32m     54\u001B[0m \n\u001B[0;32m     55\u001B[0m \u001B[38;5;66;03m# predict_weapon_video('C:/Users/mupaj/Documents/Apps/final_vc/data/pexels-erica-hotaru-5933320-1920x1080-50fps.mp4')\u001B[39;00m\n\u001B[1;32m---> 56\u001B[0m \u001B[43mpredict_weapon_video\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mC:/Users/mupaj/Documents/Apps/final_vc/data/180925_02_01_preview.mp4\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[23], line 28\u001B[0m, in \u001B[0;36mpredict_weapon_video\u001B[1;34m(video_path)\u001B[0m\n\u001B[0;32m     25\u001B[0m frame_expanded \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexpand_dims(normalized_frame, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     27\u001B[0m \u001B[38;5;66;03m# Use the model to predict the weapon\u001B[39;00m\n\u001B[1;32m---> 28\u001B[0m prediction \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe_expanded\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     29\u001B[0m label \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(prediction)\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m# Get the label name from the train generator's class_indices\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Apps\\final_vc\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Documents\\Apps\\final_vc\\venv\\lib\\site-packages\\keras\\engine\\training.py:2349\u001B[0m, in \u001B[0;36mModel.predict\u001B[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   2340\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[0;32m   2341\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   2342\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2343\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2346\u001B[0m             stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m   2347\u001B[0m         )\n\u001B[1;32m-> 2349\u001B[0m data_handler \u001B[38;5;241m=\u001B[39m \u001B[43mdata_adapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_data_handler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2352\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2353\u001B[0m \u001B[43m    \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2354\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2355\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2356\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2357\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2358\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2359\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps_per_execution\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_steps_per_execution\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2360\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2362\u001B[0m \u001B[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001B[39;00m\n\u001B[0;32m   2363\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(callbacks, callbacks_module\u001B[38;5;241m.\u001B[39mCallbackList):\n",
      "File \u001B[1;32m~\\Documents\\Apps\\final_vc\\venv\\lib\\site-packages\\keras\\engine\\data_adapter.py:1583\u001B[0m, in \u001B[0;36mget_data_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1581\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cluster_coordinator\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   1582\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _ClusterCoordinatorDataHandler(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1583\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataHandler\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Apps\\final_vc\\venv\\lib\\site-packages\\keras\\engine\\data_adapter.py:1260\u001B[0m, in \u001B[0;36mDataHandler.__init__\u001B[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001B[0m\n\u001B[0;32m   1257\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_execution \u001B[38;5;241m=\u001B[39m steps_per_execution\n\u001B[0;32m   1259\u001B[0m adapter_cls \u001B[38;5;241m=\u001B[39m select_data_adapter(x, y)\n\u001B[1;32m-> 1260\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_adapter \u001B[38;5;241m=\u001B[39m \u001B[43madapter_cls\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1261\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1262\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1263\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1264\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1265\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1266\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1270\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdistribution_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistribute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_strategy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1272\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1273\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1275\u001B[0m strategy \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdistribute\u001B[38;5;241m.\u001B[39mget_strategy()\n\u001B[0;32m   1277\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32m~\\Documents\\Apps\\final_vc\\venv\\lib\\site-packages\\keras\\engine\\data_adapter.py:346\u001B[0m, in \u001B[0;36mTensorLikeDataAdapter.__init__\u001B[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001B[0m\n\u001B[0;32m    343\u001B[0m         flat_dataset \u001B[38;5;241m=\u001B[39m flat_dataset\u001B[38;5;241m.\u001B[39mshuffle(\u001B[38;5;241m1024\u001B[39m)\u001B[38;5;241m.\u001B[39mrepeat(epochs)\n\u001B[0;32m    344\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m flat_dataset\n\u001B[1;32m--> 346\u001B[0m indices_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mindices_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_map\u001B[49m\u001B[43m(\u001B[49m\u001B[43mslice_batch_indices\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    348\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mslice_inputs(indices_dataset, inputs)\n\u001B[0;32m    350\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m shuffle \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\Documents\\Apps\\final_vc\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2285\u001B[0m, in \u001B[0;36mDatasetV2.flat_map\u001B[1;34m(self, map_func, name)\u001B[0m\n\u001B[0;32m   2281\u001B[0m \u001B[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> flat_map_op ->\u001B[39;00m\n\u001B[0;32m   2282\u001B[0m \u001B[38;5;66;03m# dataset_ops).\u001B[39;00m\n\u001B[0;32m   2283\u001B[0m \u001B[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001B[39;00m\n\u001B[0;32m   2284\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m flat_map_op\n\u001B[1;32m-> 2285\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mflat_map_op\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_map\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Apps\\final_vc\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\flat_map_op.py:24\u001B[0m, in \u001B[0;36m_flat_map\u001B[1;34m(input_dataset, map_func, name)\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_flat_map\u001B[39m(input_dataset, map_func, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):  \u001B[38;5;66;03m# pylint: disable=unused-private-name\u001B[39;00m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001B[39;00m\n\u001B[1;32m---> 24\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_FlatMapDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Apps\\final_vc\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\flat_map_op.py:33\u001B[0m, in \u001B[0;36m_FlatMapDataset.__init__\u001B[1;34m(self, input_dataset, map_func, name)\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, input_dataset, map_func, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     32\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_input_dataset \u001B[38;5;241m=\u001B[39m input_dataset\n\u001B[1;32m---> 33\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func \u001B[38;5;241m=\u001B[39m \u001B[43mstructured_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mStructuredFunctionWrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[43m      \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_transformation_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_dataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     35\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func\u001B[38;5;241m.\u001B[39moutput_structure, dataset_ops\u001B[38;5;241m.\u001B[39mDatasetSpec):\n\u001B[0;32m     36\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m     37\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe `map_func` argument must return a `Dataset` object. Got \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     38\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdataset_ops\u001B[38;5;241m.\u001B[39mget_type(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func\u001B[38;5;241m.\u001B[39moutput_structure)\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\Apps\\final_vc\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:261\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__\u001B[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001B[0m\n\u001B[0;32m    254\u001B[0m       warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    255\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    256\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moption is set, this option does not apply to tf.data functions. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    257\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo force eager execution of tf.data functions, please use \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    258\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    259\u001B[0m     fn_factory \u001B[38;5;241m=\u001B[39m trace_tf_function(defun_kwargs)\n\u001B[1;32m--> 261\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function \u001B[38;5;241m=\u001B[39m \u001B[43mfn_factory\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    262\u001B[0m \u001B[38;5;66;03m# There is no graph to add in eager mode.\u001B[39;00m\n\u001B[0;32m    263\u001B[0m add_to_graph \u001B[38;5;241m&\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly()\n",
      "File \u001B[1;32m~\\Documents\\Apps\\final_vc\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:232\u001B[0m, in \u001B[0;36mTracingCompiler.get_concrete_function\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_concrete_function\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    224\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001B[39;00m\n\u001B[0;32m    225\u001B[0m \n\u001B[0;32m    226\u001B[0m \u001B[38;5;124;03m  Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    230\u001B[0m \u001B[38;5;124;03m      `tf.Tensor` or `tf.TensorSpec`.\u001B[39;00m\n\u001B[0;32m    231\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m--> 232\u001B[0m   concrete_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_concrete_function_garbage_collected\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    233\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    234\u001B[0m   concrete_function\u001B[38;5;241m.\u001B[39m_garbage_collector\u001B[38;5;241m.\u001B[39mrelease()  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m    235\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m concrete_function\n",
      "File \u001B[1;32m~\\Documents\\Apps\\final_vc\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:202\u001B[0m, in \u001B[0;36mTracingCompiler._get_concrete_function_garbage_collected\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    199\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_spec\u001B[38;5;241m.\u001B[39mmake_canonicalized_monomorphic_type(args, kwargs)\n\u001B[0;32m    201\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m--> 202\u001B[0m   concrete_function, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_define_concrete_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    203\u001B[0m   seen_names \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n\u001B[0;32m    204\u001B[0m   concrete_function\u001B[38;5;241m.\u001B[39m_arg_keywords \u001B[38;5;241m=\u001B[39m []  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Apps\\final_vc\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:166\u001B[0m, in \u001B[0;36mTracingCompiler._maybe_define_concrete_function\u001B[1;34m(self, args, kwargs)\u001B[0m\n\u001B[0;32m    163\u001B[0m   args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_signature\n\u001B[0;32m    164\u001B[0m   kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m--> 166\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_define_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Apps\\final_vc\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:396\u001B[0m, in \u001B[0;36mTracingCompiler._maybe_define_function\u001B[1;34m(self, args, kwargs)\u001B[0m\n\u001B[0;32m    393\u001B[0m   args \u001B[38;5;241m=\u001B[39m placeholder_bound_args\u001B[38;5;241m.\u001B[39margs\n\u001B[0;32m    394\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m placeholder_bound_args\u001B[38;5;241m.\u001B[39mkwargs\n\u001B[1;32m--> 396\u001B[0m concrete_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_concrete_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    397\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc_graph\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    399\u001B[0m \u001B[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001B[39;00m\n\u001B[0;32m    400\u001B[0m graph_capture_container \u001B[38;5;241m=\u001B[39m concrete_function\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39m_function_captures  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Apps\\final_vc\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:299\u001B[0m, in \u001B[0;36mTracingCompiler._create_concrete_function\u001B[1;34m(self, args, kwargs, func_graph)\u001B[0m\n\u001B[0;32m    296\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    297\u001B[0m   arg_names \u001B[38;5;241m=\u001B[39m base_arg_names\n\u001B[1;32m--> 299\u001B[0m concrete_function \u001B[38;5;241m=\u001B[39m \u001B[43mmonomorphic_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mConcreteFunction\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    300\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfunc_graph_module\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc_graph_from_py_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    301\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    302\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_python_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    303\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    304\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    305\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    306\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    307\u001B[0m \u001B[43m        \u001B[49m\u001B[43mautograph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_autograph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    308\u001B[0m \u001B[43m        \u001B[49m\u001B[43mautograph_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_autograph_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    309\u001B[0m \u001B[43m        \u001B[49m\u001B[43marg_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43marg_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    310\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapture_by_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_capture_by_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    311\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcreate_placeholders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    312\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_function_attributes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    313\u001B[0m \u001B[43m    \u001B[49m\u001B[43mspec\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_spec\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    314\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001B[39;49;00m\n\u001B[0;32m    315\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# scope. This is not the default behavior since it gets used in some\u001B[39;49;00m\n\u001B[0;32m    316\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# places (like Keras) where the FuncGraph lives longer than the\u001B[39;49;00m\n\u001B[0;32m    317\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# ConcreteFunction.\u001B[39;49;00m\n\u001B[0;32m    318\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshared_func_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    319\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m concrete_function\n",
      "File \u001B[1;32m~\\Documents\\Apps\\final_vc\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1362\u001B[0m, in \u001B[0;36mConcreteFunction.__init__\u001B[1;34m(self, func_graph, attrs, shared_func_graph, spec)\u001B[0m\n\u001B[0;32m   1356\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_garbage_collector \u001B[38;5;241m=\u001B[39m ConcreteFunctionGarbageCollector(func_graph)\n\u001B[0;32m   1358\u001B[0m \u001B[38;5;66;03m# Pairs of forward and backward functions used for computing gradients.\u001B[39;00m\n\u001B[0;32m   1359\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m   1360\u001B[0m \u001B[38;5;66;03m# These each get a reference to the FuncGraph deleter since they use the\u001B[39;00m\n\u001B[0;32m   1361\u001B[0m \u001B[38;5;66;03m# FuncGraph directly.\u001B[39;00m\n\u001B[1;32m-> 1362\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_delayed_rewrite_functions \u001B[38;5;241m=\u001B[39m \u001B[43m_DelayedRewriteGradientFunctions\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1363\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfunc_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_attrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_garbage_collector\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1364\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_first_order_tape_functions \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m   1365\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_higher_order_tape_functions \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[1;32m~\\Documents\\Apps\\final_vc\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:466\u001B[0m, in \u001B[0;36m_DelayedRewriteGradientFunctions.__init__\u001B[1;34m(self, func_graph, attrs, func_graph_deleter)\u001B[0m\n\u001B[0;32m    464\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cached_function_pairs \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    465\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_func_graph \u001B[38;5;241m=\u001B[39m func_graph\n\u001B[1;32m--> 466\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inference_function \u001B[38;5;241m=\u001B[39m \u001B[43m_EagerDefinedFunction\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    467\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_inference_name\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func_graph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    468\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func_graph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func_graph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    469\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_attrs \u001B[38;5;241m=\u001B[39m attrs\n\u001B[0;32m    470\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Apps\\final_vc\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:252\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.__init__\u001B[1;34m(self, name, graph, inputs, outputs, attrs)\u001B[0m\n\u001B[0;32m    246\u001B[0m   pywrap_tf_session\u001B[38;5;241m.\u001B[39mTF_FunctionSetAttrValueProto(fn, compat\u001B[38;5;241m.\u001B[39mas_str(name),\n\u001B[0;32m    247\u001B[0m                                                  serialized)\n\u001B[0;32m    249\u001B[0m \u001B[38;5;66;03m# NOTE(feyu): Do not cache signature and definition at initialization to\u001B[39;00m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;66;03m# save memory usage of concrete functions never called through Python. We\u001B[39;00m\n\u001B[0;32m    251\u001B[0m \u001B[38;5;66;03m# cache them on the first call of .definition and .signature.\u001B[39;00m\n\u001B[1;32m--> 252\u001B[0m signature \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_definition\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msignature\n\u001B[0;32m    254\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_name \u001B[38;5;241m=\u001B[39m compat\u001B[38;5;241m.\u001B[39mas_bytes(signature\u001B[38;5;241m.\u001B[39mname)\n\u001B[0;32m    255\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39minit_scope():\n",
      "File \u001B[1;32m~\\Documents\\Apps\\final_vc\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:295\u001B[0m, in \u001B[0;36m_EagerDefinedFunction._get_definition\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    293\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m c_api_util\u001B[38;5;241m.\u001B[39mtf_buffer() \u001B[38;5;28;01mas\u001B[39;00m buffer_:\n\u001B[0;32m    294\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_c_func\u001B[38;5;241m.\u001B[39mget() \u001B[38;5;28;01mas\u001B[39;00m func:\n\u001B[1;32m--> 295\u001B[0m     \u001B[43mpywrap_tf_session\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTF_FunctionToFunctionDef\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer_\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    296\u001B[0m   proto_data \u001B[38;5;241m=\u001B[39m pywrap_tf_session\u001B[38;5;241m.\u001B[39mTF_GetBuffer(buffer_)\n\u001B[0;32m    297\u001B[0m function_def \u001B[38;5;241m=\u001B[39m function_pb2\u001B[38;5;241m.\u001B[39mFunctionDef()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Weapon detection in video\n",
    "\"\"\"\n",
    "\n",
    "def predict_weapon_video(video_path):\n",
    "    # Open the video file\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    while(video.isOpened()):\n",
    "        # Read a frame\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the frame color\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Resize the frame to the size your model expects\n",
    "        resized_frame = cv2.resize(frame_rgb, (150, 150))\n",
    "\n",
    "        # Normalize the frame\n",
    "        normalized_frame = resized_frame / 255.0\n",
    "\n",
    "        # Expand dimensions to match the shape the model expects\n",
    "        frame_expanded = np.expand_dims(normalized_frame, axis=0)\n",
    "\n",
    "        # Use the model to predict the weapon\n",
    "        prediction = model.predict(frame_expanded)\n",
    "        label = np.argmax(prediction)\n",
    "\n",
    "        # Get the label name from the train generator's class_indices\n",
    "        label_name = list(train_generator.class_indices.keys())[\n",
    "            list(train_generator.class_indices.values()).index(label)]\n",
    "\n",
    "        print(f\"Label: {label_name} - Prediction: {prediction}\")\n",
    "        # Add a label to the frame\n",
    "        cv2.putText(frame, label_name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        # Break the loop on 'q' press\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # When everything is done, release the video capture and video write objects\n",
    "    video.release()\n",
    "\n",
    "    # Close all the frames\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# predict_weapon_video('C:/Users/mupaj/Documents/Apps/final_vc/data/pexels'\n",
    "#                    '-karolina-grabowska-5243196-1920x1080-25fps.mp4')\n",
    "\n",
    "# predict_weapon_video('C:/Users/mupaj/Documents/Apps/final_vc/data/pexels-erica-hotaru-5933320-1920x1080-50fps.mp4')\n",
    "predict_weapon_video('C:/Users/mupaj/Documents/Apps/final_vc/data/180925_02_01_preview.mp4')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T17:21:31.493861Z",
     "end_time": "2023-05-19T17:21:31.647299Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
